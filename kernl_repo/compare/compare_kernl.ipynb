{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizer in /usr/local/lib/python3.9/dist-packages (3.4.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mSun Jan  8 03:07:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.76.02    Driver Version: 517.48       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   30C    P8    23W / 350W |    827MiB / 24576MiB |     11%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! pip install tokenizer sentencepiece\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import time\n",
    "import torch._dynamo as torchdynamo\n",
    "import torch\n",
    "from kernl.model_optimization import optimize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# default cache size needs to be increased to store the many graphs with generative models\n",
    "torchdynamo.config.cache_size_limit = 512\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.eval().cuda()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\n",
    "    \"translate English to French: The house in the woods is wonderful, can we buy it ?\",\n",
    "    return_tensors=\"pt\",\n",
    "    pad_to_multiple_of=8,\n",
    "    padding=True,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "0.5384220600128173 s / inference\n"
     ]
    }
   ],
   "source": [
    "# vanilla\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    output = model.generate(\n",
    "        inputs=input_ids[\"input_ids\"],\n",
    "        min_length=22,\n",
    "        max_length=22,\n",
    "    )\n",
    "    print(tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "end = time.time()\n",
    "print(f'{(end - start) / 10} s / inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "0.34462134838104247 s / inference\n"
     ]
    }
   ],
   "source": [
    "# vanilla inference mode\n",
    "with torch.inference_mode():\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        output = model.generate(\n",
    "            inputs=input_ids[\"input_ids\"],\n",
    "            min_length=22,\n",
    "            max_length=22,\n",
    "        )\n",
    "        print(tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "    end = time.time()\n",
    "    print(f'{(end - start) / 10} s / inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/_dynamo/eval_frame.py:372: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled.Consider setting `torch.set_float32_matmul_precision('high')`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dynamo optimize\n",
    "model.generate2 = torchdynamo.optimize(\"inductor\")(model.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 271, in call_method\n",
      "    return getattr(self_obj, target)(*args_tail, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %view : [#users=1] = call_method[target=view](args = (%inputs_tensor, -1, 24), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_encoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 932, in forward\n",
      "    input_ids = input_ids.view(-1, input_shape[-1])\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py\", line 601, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)\n",
      "\n",
      "[2023-01-08 02:59:14,229] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 02:59:29,185] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,219] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,244] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,269] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,294] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,320] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,343] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,366] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,388] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,412] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,434] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:29,459] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:30,194] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 02:59:35,938] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:35,982] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,019] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,055] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,093] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,130] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,166] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,205] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,243] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,280] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,315] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,351] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:36,964] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 02:59:42,797] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:42,843] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:42,880] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:42,917] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:42,955] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:42,994] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,030] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,069] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,108] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,147] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,185] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,221] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:43,801] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 02:59:49,568] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,626] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,664] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,703] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,742] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,782] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,820] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,859] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,898] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,939] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:49,977] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:50,016] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:50,706] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 02:59:56,572] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,625] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,664] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,705] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,745] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,785] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,823] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,861] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,900] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,939] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:56,977] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:57,015] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 02:59:57,649] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:03,768] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:03,818] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:03,862] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:03,907] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:03,949] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:03,990] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,028] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,068] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,108] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,148] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,186] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,228] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:04,911] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:10,914] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:10,964] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,004] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,043] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,083] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,124] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,162] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,214] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,258] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,299] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,338] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,379] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:11,952] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:17,974] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,016] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,052] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,088] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,125] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,165] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,201] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,237] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,272] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,308] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,344] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:18,378] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:19,099] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:24,892] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:24,936] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:24,974] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,009] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,043] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,077] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,110] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,144] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,179] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,213] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,247] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:25,281] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:26,009] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:31,686] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,730] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,764] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,798] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,838] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,881] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,920] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,956] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:31,992] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:32,028] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:32,062] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:32,097] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:32,787] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:38,649] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,692] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,728] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,763] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,798] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,834] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,868] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,902] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,937] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:38,972] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:39,010] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:39,044] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:39,692] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:45,429] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,472] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,507] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,541] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,576] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,611] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,648] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,686] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,720] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,755] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,789] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:45,828] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:46,481] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:52,098] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,142] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,177] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,215] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,250] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,284] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,318] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,352] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,387] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,422] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,456] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:52,491] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:53,147] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:00:58,752] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,794] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,828] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,861] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,896] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,929] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,963] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:58,996] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:59,030] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:59,063] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:59,096] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:59,128] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:00:59,777] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:05,432] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,474] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,507] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,542] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,577] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,612] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,645] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,678] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,712] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,745] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,779] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:05,813] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:06,498] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:12,165] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,211] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,248] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,282] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,317] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,351] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,384] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,419] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,453] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,489] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,522] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:12,556] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:13,218] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:18,839] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:18,877] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:18,909] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:18,941] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:18,972] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,009] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,043] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,076] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,109] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,140] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,171] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:19,203] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:20,014] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:25,795] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:25,835] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:25,869] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:25,902] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:25,937] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:25,971] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,007] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,046] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,081] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,116] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,149] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,184] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:26,956] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:32,717] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,773] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,808] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,842] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,877] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,911] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,944] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:32,978] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:33,012] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:33,047] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:33,100] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:33,162] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:33,924] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:39,607] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,649] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,682] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,715] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,749] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,784] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,818] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,852] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,886] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,920] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,953] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:39,987] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:40,783] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "Failed to collect metadata on function, produced code may be suboptimal.  Known situations this can occur are inference mode only compilation involving resize_ or prims (!schema.hasAnyAliasInfo() INTERNAL ASSERT FAILED); if your situation looks different please file a bug to PyTorch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 1273, in aot_wrapper_dedupe\n",
      "    fw_metadata, _out, _num_aliasing_metadata_outs = run_functionalized_fw_and_collect_metadata(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 289, in inner\n",
      "    outs = f(*f_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_functorch/aot_autograd.py\", line 2327, in functional_call\n",
      "    out = Interpreter(mod).run(*args[params_len:], **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 136, in run\n",
      "    self.env[node] = self.run_node(node)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 177, in run_node\n",
      "    return getattr(self, n.op)(n.target, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/fx/interpreter.py\", line 294, in call_module\n",
      "    return submod(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1482, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/_inductor/overrides.py\", line 36, in __torch_function__\n",
      "    return func(*args, **kwargs)\n",
      "RuntimeError: Inference tensors do not track version counter.\n",
      "\n",
      "While executing %self_decoder_block_0_layer_0_self_attention_q : [#users=1] = call_module[target=self_decoder_block_0_layer_0_SelfAttention_q](args = (%mul_4,), kwargs = {})\n",
      "Original traceback:\n",
      "Module stack: {'self_decoder': \"<class 'transformers.models.t5.modeling_t5.T5Stack'>\", 'self_decoder_block_0': \"<class 'transformers.models.t5.modeling_t5.T5Block'>\", 'sub0_0': \"<class 'transformers.models.t5.modeling_t5.T5LayerSelfAttention'>\", 'self_decoder_block_0_layer_0_SelfAttention': \"<class 'transformers.models.t5.modeling_t5.T5Attention'>\", 'self_decoder_block_0_layer_0_SelfAttention_q': \"<class 'torch.nn.modules.linear.Linear'>\"}\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 498, in forward\n",
      "    query_states = shape(self.q(hidden_states))  # (batch_size, n_heads, seq_length, dim_per_head)\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 579, in forward\n",
      "    attention_output = self.SelfAttention(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 673, in forward\n",
      "    self_attention_outputs = self.layer[0](\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1040, in forward\n",
      "    layer_outputs = layer_module(\n",
      " |   File \"/usr/local/lib/python3.9/dist-packages/transformers/models/t5/modeling_t5.py\", line 1648, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/utils/stateless.py:44: UserWarning: functional_call was passed multiple values for tied weights. This behavior is deprecated and will be an error in future versions\n",
      "  warnings.warn(\"functional_call was passed multiple values for tied weights. \"\n",
      "[2023-01-08 03:01:46,500] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,543] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,576] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,610] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,644] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,681] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,714] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,749] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,787] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,821] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,856] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:46,890] torch._inductor.optimize_indexing: [WARNING] unhandled ValueRange op name\n",
      "[2023-01-08 03:01:47,616] torch._inductor.compile_fx: [WARNING] skipping cudagraphs due to input mutation\n"
     ]
    }
   ],
   "source": [
    "# dynamo warm up\n",
    "with torch.inference_mode():\n",
    "    output = model.generate2(\n",
    "        inputs=input_ids[\"input_ids\"],\n",
    "        min_length=22,\n",
    "        max_length=22,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "La maison dans les bois est merveilleuse, pouvons-nous l'acheter? \n",
      "0.0711198091506958 s / inference\n"
     ]
    }
   ],
   "source": [
    "# dynamo inference mode\n",
    "with torch.inference_mode():\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        output = model.generate2(\n",
    "            inputs=input_ids[\"input_ids\"],\n",
    "            min_length=22,\n",
    "            max_length=22,\n",
    "        )\n",
    "        print(tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "    end = time.time()\n",
    "    print(f'{(end - start) / 10} s / inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernl optimize\n",
    "optimize_model(model.encoder)\n",
    "optimize_model(model.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163.17514570000276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kernl warmup with fp16\n",
    "with torch.inference_mode(), torch.autocast(dtype=torch.float16, cache_enabled=True, device_type=\"cuda\"):\n",
    "    start = time.perf_counter()\n",
    "    output = model.generate(inputs=input_ids[\"input_ids\"], min_length=22, max_length=22)\n",
    "    print(time.perf_counter() - start)\n",
    "    print(tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.09205513000488282 s / inference\n"
     ]
    }
   ],
   "source": [
    "# kernl inference model fp16\n",
    "with torch.inference_mode(), torch.autocast(dtype=torch.float16, cache_enabled=True, device_type=\"cuda\"):\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        output = model.generate(\n",
    "            inputs=input_ids[\"input_ids\"],\n",
    "            min_length=22,\n",
    "            max_length=22,\n",
    "        )\n",
    "        print(tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "end = time.time()\n",
    "print(f'{(end - start) / 10} s / inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
